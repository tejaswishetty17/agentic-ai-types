{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/V+11Uo9ahBOZA3+TsWmy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tejaswishetty17/Agentic-AI/blob/main/Calling_Agents_6(Maintaining%20running%20summary).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chat with message summarization\n",
        "\n",
        "**Maintaining running summary**\n",
        "\n",
        "\n",
        ">Lets say if the number of messages are growing beyond a certain threshold then summarize the conversation to maintain the contex. This allows us to reatain a compressed representation of the full conversation, rather than just removing it with filtering. This reduce the number of tokens on each queries sent to the LLM.\n",
        "\n",
        ">Lets incorporate this summarization into a simple Chatbot.\n",
        "And we'll equip that Chatbot with memory, supporting long-running conversation without incurring high token cost/latency\n"
      ],
      "metadata": {
        "id": "ndhgiUlH_X1F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TtX8BKo_Hgf",
        "outputId": "f8a93d73-e957-45b2-98d5-c4940925e0b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m687.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "pip install -q langchain langchain_openai langchain_community langgraph langchain-core"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"add your key\""
      ],
      "metadata": {
        "id": "m33FF7SVCLnN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
      ],
      "metadata": {
        "id": "n_rH_XbNCSzV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> We'll use `MessageState`, as before.\n",
        "In addition to the built-in `messages` key, we'll now include custom key (`summary`)"
      ],
      "metadata": {
        "id": "dMk_wbhhCy5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import MessagesState\n",
        "class State(MessagesState):\n",
        "  summary:str"
      ],
      "metadata": {
        "id": "AcaTVyt1CbvR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> We'll define a node to call our LLM that incorporates a summary, if it exists, into the prompt."
      ],
      "metadata": {
        "id": "NWEdHl5DEAVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
        "\n",
        "#Define the logic to call the model\n",
        "def call_model(state: State) -> State:\n",
        "\n",
        "  #get summary if it exists\n",
        "  summary = state.get(\"summary\", \"\")\n",
        "\n",
        "  #If there is summmary, then we do this\n",
        "  if summary:\n",
        "\n",
        "    #Add summary to system message\n",
        "    system_message = f\"Summary of conversation earlier: {summary}\"\n",
        "\n",
        "    #Apend summary to any newer messages\n",
        "    messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
        "\n",
        "  else:\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "  response = model.invoke(messages)\n",
        "  return {\"messages\":response}"
      ],
      "metadata": {
        "id": "k9pk5C_NDXQA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> We'll define a node to produce a summary\n",
        "\n",
        "Note, here we'll use `RemoveMessage` to filter our state after we've produced the summary\n"
      ],
      "metadata": {
        "id": "-LsQ9XCRFxky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_conversation(state: State):\n",
        "\n",
        "  #First, we get any existing summary\n",
        "  summary = state.get(\"summary\", \"\")\n",
        "\n",
        "  #Create our summarization prompt\n",
        "  if summary:\n",
        "\n",
        "    # if summary already exists\n",
        "    summary_message = (\n",
        "        f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
        "        \"Extend the summary by taking into account the new messages above:\"\n",
        "    )\n",
        "  else:\n",
        "    summary_message = \"Create a summary of the conversation above:\"\n",
        "\n",
        "  #Add prompt to our history\n",
        "  messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
        "  response = model.invoke(messages)\n",
        "\n",
        "  #Delete all but the 2 most recent messages\n",
        "  delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
        "  return {\"summary\": response.content, \"messages\":delete_messages}\n",
        ""
      ],
      "metadata": {
        "id": "Rg-18A6iFtN4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> We'll add a conditional edge to determine whether to produce a summary based on the conversation length."
      ],
      "metadata": {
        "id": "LfO_2i0eIilH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END\n",
        "#Determine whether to end or summarize the conversation\n",
        "def should_continue(state: State)->State:\n",
        "  \"\"\"Return the next node to execute. \"\"\"\n",
        "\n",
        "  messages = state[\"messages\"]\n",
        "\n",
        "  # If there are more than six messages, then we summarize the conversation\n",
        "  if len(messages)>6:\n",
        "    return \"summarize_conversation\"\n",
        "  # Otherwise we can just end\n",
        "  return END"
      ],
      "metadata": {
        "id": "syJ58nD0IhCv"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import StateGraph, START\n",
        "\n",
        "# Define a new graph\n",
        "workflow = StateGraph(State)\n",
        "workflow.add_node(\"conversation\", call_model)\n",
        "workflow.add_node(summarize_conversation)\n",
        "\n",
        "# Set the entrypoint as conversation\n",
        "workflow.add_edge(START, \"conversation\")\n",
        "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
        "workflow.add_edge(\"summarize_conversation\", END)\n",
        "\n",
        "# Compile\n",
        "memory = MemorySaver()\n",
        "graph = workflow.compile(checkpointer=memory)\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "1-svgk32JpfY",
        "outputId": "6a72a216-2f39-473a-8c16-bc3883cfa8a4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create a thread\n",
        "config = {\"configurable\": {\"thread_id\":\"1\"}}\n",
        "\n",
        "#State conversation\n",
        "input_message = HumanMessage(content = \"Hi! I am Tejaswi\")\n",
        "output = graph.invoke({\"messages\": [input_message]}, config)\n",
        "for m in output['messages'][-1:]:\n",
        "  m.pretty_print()\n",
        "\n",
        "input_message = HumanMessage(content = \"What is the LLM?\")\n",
        "output = graph.invoke({\"messages\": [input_message]}, config)\n",
        "for m in output['messages'][-1:]:\n",
        "  m.pretty_print()\n",
        "\n",
        "input_message = HumanMessage(content = \"I would like to know more about the use cases of LLM?\")\n",
        "output = graph.invoke({\"messages\": [input_message]}, config)\n",
        "for m in output['messages'][-1:]:\n",
        "  m.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yCaSKSyLoOx",
        "outputId": "4fe3721c-8243-4f55-bc99-90517ef79130"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hi Tejaswi! How can I assist you today?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "LLM stands for \"Large Language Model.\" It refers to a type of artificial intelligence model that is trained on vast amounts of text data to understand and generate human-like language. These models use deep learning techniques, particularly neural networks, to process and generate text based on the patterns they learn during training.\n",
            "\n",
            "Some key features of LLMs include:\n",
            "\n",
            "1. **Natural Language Understanding**: They can comprehend and respond to text inputs in a way that mimics human conversation.\n",
            "\n",
            "2. **Text Generation**: LLMs can generate coherent and contextually relevant text, making them useful for applications like chatbots, content creation, and more.\n",
            "\n",
            "3. **Versatility**: They can perform a variety of language-related tasks, such as translation, summarization, question answering, and more.\n",
            "\n",
            "4. **Scale**: The \"large\" in LLM refers to the size of the model, which typically has billions of parameters, allowing it to capture complex language patterns.\n",
            "\n",
            "Examples of LLMs include OpenAI's GPT-3 and GPT-4, Google's BERT, and others. These models have been widely adopted in various applications across industries. If you have more specific questions about LLMs or their applications, feel free to ask!\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Large Language Models (LLMs) have a wide range of use cases across various industries and applications. Here are some of the most common and impactful use cases:\n",
            "\n",
            "1. **Chatbots and Virtual Assistants**: LLMs can power conversational agents that provide customer support, answer queries, and assist users in real-time. They can handle a variety of topics and maintain context over multiple interactions.\n",
            "\n",
            "2. **Content Creation**: LLMs can generate articles, blog posts, marketing copy, and social media content. They can assist writers by providing suggestions, drafting outlines, or even writing entire pieces based on prompts.\n",
            "\n",
            "3. **Translation Services**: LLMs can be used for language translation, providing more nuanced and context-aware translations compared to traditional rule-based systems.\n",
            "\n",
            "4. **Summarization**: They can summarize long documents, articles, or reports into concise summaries, making it easier for users to grasp key points quickly.\n",
            "\n",
            "5. **Question Answering**: LLMs can be employed in systems that answer questions based on a given context or knowledge base, making them useful for educational tools, customer support, and information retrieval.\n",
            "\n",
            "6. **Sentiment Analysis**: Businesses can use LLMs to analyze customer feedback, reviews, and social media posts to gauge public sentiment about products or services.\n",
            "\n",
            "7. **Code Generation and Assistance**: LLMs can assist developers by generating code snippets, providing explanations for code, and even debugging, making programming more efficient.\n",
            "\n",
            "8. **Personalized Recommendations**: By analyzing user preferences and behavior, LLMs can help generate personalized content recommendations, such as articles, products, or services.\n",
            "\n",
            "9. **Creative Writing**: LLMs can assist in creative endeavors, such as writing poetry, stories, or scripts, by providing inspiration or generating entire pieces based on prompts.\n",
            "\n",
            "10. **Education and Tutoring**: They can serve as virtual tutors, providing explanations, answering questions, and helping students with their studies in various subjects.\n",
            "\n",
            "11. **Data Extraction and Analysis**: LLMs can extract relevant information from unstructured data sources, such as documents or web pages, and analyze it for insights.\n",
            "\n",
            "12. **Legal and Compliance**: In the legal field, LLMs can assist with document review, contract analysis, and legal research, helping lawyers save time and improve accuracy.\n",
            "\n",
            "13. **Healthcare**: LLMs can be used to analyze medical literature, assist in patient communication, and even help in diagnosing conditions based on patient descriptions.\n",
            "\n",
            "These use cases demonstrate the versatility and potential of LLMs in transforming how we interact with technology and information. As the technology continues to evolve, new applications and improvements are likely to emerge. If you have a specific area of interest or application in mind, let me know, and I can provide more detailed information!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we don't yet have a summary of the state because we still have < = 6 messages.\n",
        "\n",
        "This was set in `should_continue`.\n",
        "\n",
        "```\n",
        "    # If there are more than six messages, then we summarize the conversation\n",
        "    if len(messages) > 6:\n",
        "        return \"summarize_conversation\"\n",
        "```\n",
        "\n",
        "We can pick up the conversation because we have the thread."
      ],
      "metadata": {
        "id": "7NvL_qSbOBTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph.get_state(config).values.get(\"summary\",\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wh3TiLNTOB-Z",
        "outputId": "e75bbf4a-aeab-4583-8b01-d2c0f76d7fb2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `config` with thread ID allows us to proceed from the previously logged state!"
      ],
      "metadata": {
        "id": "PV9yBLubONQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = HumanMessage(content = \"how do I use Langchain while using LLMs?\")\n",
        "output = graph.invoke({\"messages\": [input_message]}, config)\n",
        "for m in output['messages'][-1:]:\n",
        "  m.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNyf_spoOI0i",
        "outputId": "fe855c77-8a9c-4cb1-9c6c-072d15392499"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "LangChain is a framework designed to facilitate the development of applications that utilize Large Language Models (LLMs). It provides tools and abstractions to help you build applications that can interact with LLMs more effectively. Here’s a general guide on how to use LangChain with LLMs:\n",
            "\n",
            "### 1. **Installation**\n",
            "\n",
            "First, you need to install LangChain. You can do this using pip:\n",
            "\n",
            "```bash\n",
            "pip install langchain\n",
            "```\n",
            "\n",
            "### 2. **Setting Up an LLM**\n",
            "\n",
            "LangChain supports various LLMs, including OpenAI's GPT models, Hugging Face models, and others. You need to set up the LLM you want to use. For example, if you are using OpenAI's GPT-3 or GPT-4, you will need an API key.\n",
            "\n",
            "Here’s how to set up an OpenAI LLM:\n",
            "\n",
            "```python\n",
            "from langchain.llms import OpenAI\n",
            "\n",
            "# Initialize the OpenAI LLM\n",
            "llm = OpenAI(api_key='your_openai_api_key')\n",
            "```\n",
            "\n",
            "### 3. **Creating a Chain**\n",
            "\n",
            "LangChain allows you to create chains that define how inputs are processed and how outputs are generated. A simple chain might just involve sending a prompt to the LLM and getting a response.\n",
            "\n",
            "```python\n",
            "from langchain.chains import LLMChain\n",
            "from langchain.prompts import PromptTemplate\n",
            "\n",
            "# Define a prompt template\n",
            "prompt_template = PromptTemplate(\n",
            "    input_variables=[\"input_text\"],\n",
            "    template=\"What is the summary of the following text? {input_text}\"\n",
            ")\n",
            "\n",
            "# Create a chain\n",
            "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
            "```\n",
            "\n",
            "### 4. **Using the Chain**\n",
            "\n",
            "You can now use the chain to generate responses based on your input.\n",
            "\n",
            "```python\n",
            "# Example input text\n",
            "input_text = \"LangChain is a framework for developing applications powered by LLMs.\"\n",
            "\n",
            "# Get the response\n",
            "response = chain.run(input_text=input_text)\n",
            "print(response)\n",
            "```\n",
            "\n",
            "### 5. **Advanced Features**\n",
            "\n",
            "LangChain also supports more advanced features, such as:\n",
            "\n",
            "- **Memory**: To maintain context across multiple interactions.\n",
            "- **Agents**: To create more complex workflows that can make decisions based on user input.\n",
            "- **Document Loaders**: To load and process documents for tasks like summarization or question answering.\n",
            "\n",
            "### Example of Using Memory\n",
            "\n",
            "```python\n",
            "from langchain.memory import ConversationBufferMemory\n",
            "\n",
            "# Initialize memory\n",
            "memory = ConversationBufferMemory()\n",
            "\n",
            "# Create a chain with memory\n",
            "chain_with_memory = LLMChain(llm=llm, prompt=prompt_template, memory=memory)\n",
            "\n",
            "# Use the chain\n",
            "response1 = chain_with_memory.run(input_text=\"Tell me about LangChain.\")\n",
            "response2 = chain_with_memory.run(input_text=\"What else can it do?\")\n",
            "```\n",
            "\n",
            "### 6. **Deployment**\n",
            "\n",
            "Once you have your application working locally, you can deploy it using various platforms, such as Flask for web applications, or integrate it into existing systems.\n",
            "\n",
            "### 7. **Documentation and Community**\n",
            "\n",
            "For more detailed information, examples, and advanced usage, refer to the [LangChain documentation](https://langchain.readthedocs.io/en/latest/). The community around LangChain is also active, so you can find support and share ideas on platforms like GitHub and Discord.\n",
            "\n",
            "### Conclusion\n",
            "\n",
            "LangChain provides a powerful and flexible way to work with LLMs, making it easier to build applications that leverage the capabilities of these models. By following the steps above, you can start creating your own applications using LangChain and LLMs. If you have specific use cases or questions, feel free to ask!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph.get_state(config).values.get(\"summary\",\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "7Oshpyc8Odke",
        "outputId": "0ef7cede-13e1-4877-918c-14bf1630beee"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"In this conversation, you inquired about Large Language Models (LLMs) and their use cases. I provided an overview of LLMs, explaining their capabilities in natural language understanding, text generation, and various applications such as chatbots, content creation, translation, summarization, and more.\\n\\nYou then asked about using LangChain with LLMs. I outlined the steps to get started with LangChain, including installation, setting up an LLM (specifically OpenAI's models), creating a chain with a prompt template, and using that chain to generate responses. I also mentioned advanced features like memory and agents, and provided a brief example of using memory in a conversation. Finally, I suggested referring to the LangChain documentation for more detailed information and community support.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}